{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests, pickle\n",
    "import numpy as np, pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    sleep(1)\n",
    "    page = requests.get(url, headers = {'user-agent': 'Mozilla/5.0'})\n",
    "    \n",
    "    return BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_games_links(soup):\n",
    "    games_list = soup.find('div', class_='product_condensed')\n",
    "    links = []\n",
    "    for game in games_list.select('li[class*=\"product game_product\"]'):\n",
    "        links.append(game.a['href'])\n",
    "        \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_game_info(soup):\n",
    "    title = soup.find('div', class_='product_title').find('h1').get_text()\n",
    "    platform = soup.find('span', class_='platform').find('a').get_text().strip()\n",
    "    summary = soup.find('span', class_='blurb blurb_expanded')\n",
    "    if summary is not None:\n",
    "        summary = summary.get_text().strip()\n",
    "    else:\n",
    "        summary = soup.find('span', itemprop='description')\n",
    "        if summary is not None:\n",
    "            summary = summary.get_text().strip()\n",
    "        else:\n",
    "            summary = np.nan\n",
    "    release_date = soup.find('span', itemprop='datePublished').get_text().strip()\n",
    "    developer = soup.find('li', class_='summary_detail developer')\n",
    "    if developer is not None:\n",
    "        developer = developer.find('span', class_='data').get_text().strip()\n",
    "    else:\n",
    "        developer = np.nan\n",
    "    genre = []\n",
    "    for g in soup.find('li', class_='summary_detail product_genre').find_all('span', class_='data'): \n",
    "        genre.append(g.get_text().strip())\n",
    "\n",
    "    rating = soup.find('li', class_='summary_detail product_rating')\n",
    "    if rating is not None: \n",
    "        rating = rating.find('span', class_='data').get_text().strip() \n",
    "    else:\n",
    "        rating = np.nan\n",
    "    \n",
    "    return title, platform, summary, release_date, developer, genre, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_reviews_overview(soup):\n",
    "    overview = soup.find('span', class_='desc').get_text().strip()\n",
    "    reviews_count = soup.find('div', class_='score_distribution')\n",
    "    if reviews_count is not None:\n",
    "        reviews_count = reviews_count.find_all('span', class_='count')\n",
    "        pos = reviews_count[0].get_text().strip()\n",
    "        mixed = reviews_count[1].get_text().strip()\n",
    "        neg = reviews_count[2].get_text().strip()\n",
    "    else:\n",
    "        pos = '0'; mixed = '0'; neg = '0'\n",
    "    \n",
    "    return overview, pos, mixed, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_reviews(soup, category = 'user'):\n",
    "    names = []; dates = []; scores = []; texts = []\n",
    "    \n",
    "    reviews_list = soup.find('ol', class_=f'reviews {category}_reviews')\n",
    "    if reviews_list is not None:\n",
    "        for review in reviews_list.select(f'li[class*=\"review {category}_review\"]'):\n",
    "            if category == 'user':\n",
    "                names.append(review.find('div', class_='name').get_text().strip())\n",
    "            else:\n",
    "                names.append(review.find('div', class_='source').get_text().strip())\n",
    "            dates.append(review.find('div', class_='date').get_text().strip())\n",
    "            scores.append(review.find('div', class_='review_grade').get_text().strip())\n",
    "            exp = review.find('span', class_='blurb blurb_expanded')\n",
    "            if exp is None:\n",
    "                texts.append(review.find('div', class_='review_body').get_text().strip())\n",
    "            else:\n",
    "                texts.append(exp.get_text().strip())\n",
    "\n",
    "    return names, dates, scores, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "letters = ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', \n",
    "           'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#console = 'ps4'\n",
    "#console = 'xboxone'\n",
    "console = 'switch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "games_links = []\n",
    "\n",
    "for letter in letters:\n",
    "    soup = get_soup(f'http://www.metacritic.com/browse/games/title/{console}/{letter}')\n",
    "    games_links += get_games_links(soup)\n",
    "    p = soup.find('ul', class_='pages')\n",
    "    if p is not None: \n",
    "        pages_qty = len(p.find_all('li'))\n",
    "        for page_num in range(1, pages_qty):\n",
    "            soup = get_soup(f'http://www.metacritic.com/browse/games/title/{console}/{letter}?page={page_num}')\n",
    "            games_links += get_games_links(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickle.dump(games_links, open(f'{console}_games_links', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "games_links = pickle.load(open(f'{console}_games_links', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles = {}; platforms = {}; summaries = {}; release_dates = {} \n",
    "developers = {}; genres = {}; ratings = {}; meta_scores = {}\n",
    "meta_overviews = {}; meta_pos = {}; meta_mixed = {}\n",
    "meta_neg = {}; critics_names = {}; critics_dates = {}; critics_scores = {}\n",
    "critics_texts = {}; user_scores = {}; user_overviews = {}\n",
    "user_pos = {}; user_mixed = {}; user_neg = {}; users_names = {}\n",
    "users_dates = {}; users_scores = {}; users_texts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c434b482f374abb96f822a2acbc4ca6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar = tqdm_notebook(total=len(games_links))\n",
    "\n",
    "for link in games_links:\n",
    "    # game summary section\n",
    "    soup = get_soup(f'http://www.metacritic.com{link}')\n",
    "\n",
    "    # game summary info\n",
    "    title, platform, summary, release_date, developer, genre, rating = get_game_info(soup)\n",
    "    titles[link] = title\n",
    "    platforms[link] = platform\n",
    "    summaries[link] = summary\n",
    "    release_dates[link] = release_date\n",
    "    developers[link] = developer\n",
    "    genres[link] = genre\n",
    "    ratings[link] = rating\n",
    "    \n",
    "    # critics reviews section\n",
    "    soup = get_soup(f'http://www.metacritic.com{link}/critic-reviews')\n",
    "\n",
    "    # critics reviews general info\n",
    "    meta_score = soup.find('span', itemprop='ratingValue')\n",
    "    if meta_score is not None:\n",
    "        meta_scores[link] = meta_score.get_text().strip()\n",
    "    else:\n",
    "        meta_scores[link] = '0'\n",
    "    overview, pos, mixed, neg = get_reviews_overview(soup)\n",
    "    meta_overviews[link] =  overview\n",
    "    meta_pos[link] = pos\n",
    "    meta_mixed[link] = mixed \n",
    "    meta_neg[link] = neg\n",
    "    # critics reviews\n",
    "    names, dates, scores, texts = get_reviews(soup, 'critic')\n",
    "    critics_names[link] = names\n",
    "    critics_dates[link] = dates\n",
    "    critics_scores[link] = scores\n",
    "    critics_texts[link] = texts\n",
    "    \n",
    "    # users reviews section\n",
    "    soup = get_soup(f'http://www.metacritic.com{link}/user-reviews')\n",
    "\n",
    "    # users reviews general info\n",
    "    user_scores[link] = soup.select('div[class*=\"metascore_w user large\"]')[0].get_text().strip()\n",
    "    overview, pos, mixed, neg = get_reviews_overview(soup)\n",
    "    user_overviews[link] =  overview\n",
    "    user_pos[link] = pos\n",
    "    user_mixed[link] = mixed \n",
    "    user_neg[link] = neg\n",
    "    # users reviews\n",
    "    names, dates, scores, texts = get_reviews(soup)\n",
    "    users_names[link] = names\n",
    "    users_dates[link] = dates\n",
    "    users_scores[link] = scores\n",
    "    users_texts[link] = texts\n",
    "\n",
    "    p = soup.find('ul', class_='pages')\n",
    "    if p is not None: \n",
    "        pages_qty = len(p.find_all('li'))\n",
    "        for page_num in range(1, pages_qty):\n",
    "            sleep(randint(1,3))\n",
    "            soup = get_soup(f'http://www.metacritic.com{link}/user-reviews?page={page_num}')\n",
    "\n",
    "            names, dates, scores, texts = get_reviews(soup)\n",
    "            users_names[link] += names\n",
    "            users_dates[link] += dates\n",
    "            users_scores[link] += scores\n",
    "            users_texts[link] += texts\n",
    "    \n",
    "    bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'title': titles, 'platform': platforms, 'summary': summaries, \n",
    "                   'release_date': release_dates, 'developer': developers, 'genre': genres, \n",
    "                   'rating': ratings, 'meta_score': meta_scores, 'meta_overview': meta_overviews,\n",
    "                   'meta_pos': meta_pos, 'meta_mixed': meta_mixed, 'meta_neg': meta_neg, \n",
    "                   'user_score': user_scores, 'user_overview': user_overviews, 'user_pos': user_pos, \n",
    "                   'user_mixed': user_mixed, 'user_neg': user_neg },\n",
    "                   columns=['title', 'platform', 'developer', 'genre', 'rating', 'release_date',\n",
    "                            'summary', 'meta_score', 'meta_overview', 'meta_pos', 'meta_mixed', \n",
    "                            'meta_neg', 'user_score', 'user_overview', 'user_pos', 'user_mixed', \n",
    "                            'user_neg']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(f'{console}_games.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_reviews_df(critics_dict, dates_dict, scores_dict, texts_dict):\n",
    "    critics = []; dates = []; scores = []; texts = []; games = []; plats = []\n",
    "    for k in critics_dict:\n",
    "        critics += critics_dict[k]\n",
    "        dates += dates_dict[k]\n",
    "        scores += scores_dict[k]\n",
    "        texts += texts_dict[k]\n",
    "        games += [titles[k]] * len(critics_dict[k])\n",
    "        plats += [platforms[k]] * len(critics_dict[k])\n",
    "    \n",
    "    return pd.DataFrame({'critic': critics, 'date': dates, 'score': scores, 'text': texts, 'title': games, 'platform': plats},\n",
    "                         columns = ['score', 'text', 'critic', 'date', 'title', 'platform'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = create_reviews_df(critics_names, critics_dates, critics_scores, critics_texts)\n",
    "df.to_csv(f'{console}_meta_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = create_reviews_df(users_names, users_dates, users_scores, users_texts)\n",
    "df.to_csv(f'{console}_user_reviews.csv', index_label=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
